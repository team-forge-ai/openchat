---
alwaysApply: true
---

## OpenChat system overview

- **What this is**: OpenChat is a Tauri desktop app that chats with a local MLX model server. Frontend is React + TypeScript; data persisted in SQLite; backend is Rust/Tauri.

- **Frontend (src/)**
  - **Providers**: `MLXServerProvider` (MLX status + restart via Tauri invokes/events), `ConversationProvider` (current selection).
  - **Shell**: `AppHeader` (MLX status), `Sidebar` (shadcn/Radix; search + conversations), `ChatWindow` (messages + input).
  - **Chat flow**: If none selected, create conversation → insert user message → stream assistant (and optional reasoning) → update DB per chunk → React Query invalidations refresh UI → set conversation title after completion.
  - **Markdown**: ReactMarkdown + GFM + Math/KaTeX; Shiki code highlighting; image modal viewer; custom elements (`email-artifact`, `quick-reply`).
  - **UX**: Enter to send (Shift+Enter newline); `mod+n` new chat; `mod+b` toggle sidebar. Chat input is disabled unless MLX is running and ready.

- **Backend (src-tauri/)**
  - **MLX process manager**: `MLXServerManager` spawns `binaries/openchat-mlx-server`, finds port, health-checks `/health`, tracks `is_running/is_ready/port/pid/model_path`, emits `mlx-status-changed` events.
  - **Commands**: `mlx_get_status`, `mlx_restart`, `mlx_health_check`; port utilities for diagnostics.
  - **DB**: SQLite via `tauri-plugin-sql`; migrations create `conversations` and `messages` (with `reasoning` and `status: pending|complete|error`). Index on `messages.conversation_id`.

- **Integration points**
  - Frontend listens to `mlx-status-changed` and converts snake_case → camelCase. Invokes Tauri commands with `@tauri-apps/api/core`.
  - Streaming parser consumes SSE `data:` lines and `[DONE]` sentinel.

- **Conventions**
  - Use `@/…` imports, shadcn UI/Radix + Tailwind, TanStack Query for server state, one component per file, clear naming, no unnecessary comments.

## OpenChat system overview (always-on)

- **What this is**: OpenChat is a Tauri desktop app that chats with a local MLX model server. Frontend is React + TypeScript; data persisted in SQLite; backend is Rust/Tauri.

- **Frontend (src/)**
  - **Providers**: `MLXServerProvider` (MLX status + restart via Tauri invokes/events), `ConversationProvider` (current selection).
  - **Shell**: `AppHeader` (MLX status), `Sidebar` (shadcn/Radix; search + conversations), `ChatWindow` (messages + input).
  - **Chat flow**: If none selected, create conversation → insert user message → stream assistant (and optional reasoning) → update DB per chunk → React Query invalidations refresh UI → set conversation title after completion.
  - **Markdown**: ReactMarkdown + GFM + Math/KaTeX; Shiki code highlighting; image modal viewer; custom elements (`email-artifact`, `quick-reply`).
  - **UX**: Enter to send (Shift+Enter newline); `mod+n` new chat; `mod+b` toggle sidebar. Chat input is disabled unless MLX is running and ready.

- **Backend (src-tauri/)**
  - **MLX process manager**: `MLXServerManager` spawns `binaries/openchat-mlx-server`, finds port, health-checks `/health`, tracks `is_running/is_ready/port/pid/model_path`, emits `mlx-status-changed` events.
  - **Commands**: `mlx_get_status`, `mlx_restart`, `mlx_health_check`; port utilities for diagnostics.
  - **DB**: SQLite via `tauri-plugin-sql`; migrations create `conversations` and `messages` (with `reasoning` and `status: pending|complete|error`). Index on `messages.conversation_id`.

- **Integration points**
  - Frontend listens to `mlx-status-changed` and converts snake_case → camelCase. Invokes Tauri commands with `@tauri-apps/api/core`.
  - Streaming parser consumes SSE `data:` lines and `[DONE]` sentinel.

- **Conventions**
  - Use `@/…` imports, shadcn UI/Radix + Tailwind, TanStack Query for server state, one component per file, clear naming, no unnecessary comments.
